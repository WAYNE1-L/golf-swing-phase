import pandas as pd
import numpy as np
import os
import random
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Bidirectional
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping
import tensorflow as tf

# ==== å‚æ•° ====
CSV_PATH = "golf_swing_labeled.csv"
WINDOW_SIZE = 30
NUM_FOLDS = 5
EPOCHS = 30
BATCH_SIZE = 16

# ==== åŠ è½½æ•°æ® ====
df = pd.read_csv(CSV_PATH)
df = df[df['phase'] != 'Impact']

keypoints = list(range(33))
columns_to_use = [f'x_{i}' for i in keypoints] + [f'y_{i}' for i in keypoints]
features = df[columns_to_use]
labels = df['phase']

# ==== æ ‡ç­¾ç¼–ç  ====
le = LabelEncoder()
labels_encoded = le.fit_transform(labels)
num_classes = len(le.classes_)

# ==== æ»‘åŠ¨çª—å£å¤„ç† ====
def create_sequences(features, labels, window_size):
    X, y = [], []
    for i in range(len(features) - window_size):
        X.append(features.iloc[i:i+window_size].values)
        y.append(labels[i + window_size - 1])
    return np.array(X), np.array(y)

X, y = create_sequences(features, labels_encoded, WINDOW_SIZE)
y_cat = to_categorical(y, num_classes=num_classes)

print(f"âœ… è¾“å…¥åºåˆ—æ•°: {len(X)}, ç‰¹å¾ç»´åº¦: {X.shape[1:]}")

# ==== è®¾ç½® KFold ====
skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)
val_accuracies = []

for fold, (train_index, val_index) in enumerate(skf.split(X, y)):
    print(f"\nğŸ“¦ Fold {fold + 1}/{NUM_FOLDS}")

    # åˆ’åˆ†æ•°æ®
    X_train, X_val = X[train_index], X[val_index]
    y_train, y_val = y_cat[train_index], y_cat[val_index]

    # è®¾ç½®éšæœºç§å­ä¿è¯ä¸€è‡´æ€§
    tf.keras.utils.set_random_seed(42 + fold)

    # æ„å»ºæ¨¡å‹
    model = Sequential()
    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(WINDOW_SIZE, X.shape[2])))
    model.add(Dropout(0.3))
    model.add(Bidirectional(LSTM(64)))
    model.add(Dropout(0.3))
    model.add(Dense(num_classes, activation='softmax'))

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # è®­ç»ƒ
    early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        callbacks=[early_stop],
        verbose=0
    )

    best_val_acc = max(history.history["val_accuracy"])
    val_accuracies.append(best_val_acc)
    print(f"âœ… Fold {fold + 1} éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")

# ==== è¾“å‡ºæ€»ç»“æœ ====
mean_acc = np.mean(val_accuracies)
std_acc = np.std(val_accuracies)
print("\nğŸ¯ KæŠ˜äº¤å‰éªŒè¯å®Œæˆ")
print(f"ğŸ“Š å¹³å‡éªŒè¯å‡†ç¡®ç‡: {mean_acc:.4f}")
print(f"ğŸ“‰ æ ‡å‡†å·®: {std_acc:.4f}")
